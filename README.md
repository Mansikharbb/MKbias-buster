# MKbias-buster
 AI Fairness Evaluation Toolkit using FastAPI & Streamlit

An AI tool that evaluates prediction bias across sensitive attributes like gender using FastAPI and Streamlit.

## ğŸš€ How It Works

1. Upload a CSV file with actual, predicted values & a sensitive column (e.g., gender)
2. The backend calculates bias metrics (TPR/FPR) for each group
3. Streamlit UI shows results in real time

---

## ğŸ§ª Tech Stack

- Python
- FastAPI
- Streamlit
- Pandas
- Uvicorn

---

## ğŸ“ Project Structure
â”œâ”€â”€ .github/
MKbias-buster/
 â”œâ”€â”€ backend/ 
 â”‚ â””â”€â”€ app/ â”‚ 
 â”œâ”€â”€ main.py # FastAPI entry point â”‚
  â”œâ”€â”€ router.py # API route handlers â”‚ 
â””â”€â”€ utils/
 â”‚ â””â”€â”€ fairness_metrics.py # Bias evaluation logic
  â”œâ”€â”€ frontend/ 
  â”‚ â””â”€â”€ streamlit_app.py # Streamlit UI to upload and visualize
   â”œâ”€â”€ data/
    â”‚ â””â”€â”€ sample_data.csv # Sample dataset for testing
     â”œâ”€â”€ tests/
      â”‚ â””â”€â”€ test_fairness.py # Future unit tests
      
      â”œâ”€â”€ .gitignore # Git ignore file for Python projects
       â”œâ”€â”€ requirements.txt # Python dependencies 
       â””â”€â”€ README.md # This file

---


